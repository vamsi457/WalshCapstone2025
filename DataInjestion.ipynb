{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6324e4ce",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c9cd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from statsmodels.stats.power import FTestAnovaPower\n",
    "from statsmodels.stats.proportion import proportion_effectsize\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8daf7fb6",
   "metadata": {},
   "source": [
    "## References\n",
    "- [MindBigData Leaderboard](https://huggingface.co/spaces/DavidVivancos/MindBigData-Leaderboard)\n",
    "    - [MindBigData 2022: A Large Dataset of Brain Signals ](https://arxiv.org/pdf/2212.14746)\n",
    "        - [MindBigData](https://mindbigdata.com/opendb/)\n",
    "            - [MindBigData-MW-v1.0.zip](https://mindbigdata.com/opendb/MindBigData-MW-v1.0.zip)\n",
    "            - [MindBigData-EP-v1.0.zip](https://mindbigdata.com/opendb/MindBigData-EP-v1.0.zip)\n",
    "            - [MindBigData-MU-v1.0.zip](https://mindbigdata.com/opendb/MindBigData-MU-v1.0.zip)\n",
    "            - [MindBigData-IN-v1.06.zip](https://mindbigdata.com/opendb/MindBigData-IN-v1.06.zip)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83da56da",
   "metadata": {},
   "source": [
    "## Refresh Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5657d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef2f357",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b05af4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join('/mnt', 'd', 'work', 'Walsh', 'Capstone', 'Published', 'Data')\n",
    "prk_folder = os.path.join(data_dir, 'parquets')\n",
    "\n",
    "if not os.path.exists(prk_folder):\n",
    "    os.makedirs(prk_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115d3f3d",
   "metadata": {},
   "source": [
    "## Data directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af97e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "mbd_data_dir = os.path.join(data_dir,'MindBigData')\n",
    "mw_file = os.path.join(mbd_data_dir, 'MW.txt')\n",
    "mu_file = os.path.join(mbd_data_dir, 'MU.txt')\n",
    "in_file = os.path.join(mbd_data_dir, 'IN.txt')\n",
    "ep_file = os.path.join(mbd_data_dir, 'EP.txt')\n",
    "\n",
    "mw_pk_file = os.path.join(prk_folder, 'MW.parquet')\n",
    "mu_pk_file = os.path.join(prk_folder, 'MU.parquet')\n",
    "in_pk_file = os.path.join(prk_folder, 'IN.parquet')\n",
    "ep_pk_file = os.path.join(prk_folder, 'EP.parquet')\n",
    "\n",
    "col_headers = ['id', 'event', 'device', 'channel', 'code', 'size', 'data']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dca5f61",
   "metadata": {},
   "source": [
    "## Initializing dataframe variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eaf0654",
   "metadata": {},
   "outputs": [],
   "source": [
    "mw_df = None\n",
    "mu_df = None\n",
    "in_df = None\n",
    "ep_df = None\n",
    "\n",
    "SAMPLING_RATES = {\n",
    "    \"MW\" : 512,\n",
    "    \"EP\" : 128,\n",
    "    \"MU\" : 220,\n",
    "    \"IN\" : 128\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5087e257",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Processing MW.txt...\")\n",
    "mw_df = pd.read_csv(mw_file, header=None, names=col_headers, sep='\\\\t')\n",
    "mw_df.to_parquet(mw_pk_file, index=False)\n",
    "print(f\"Saved MW.parquet with {len(mw_df)} rows.\")\n",
    "del mw_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9ee9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Processing MU.txt...\")\n",
    "mu_df = pd.read_csv(mu_file, header=None, names=col_headers, sep='\\\\t')\n",
    "mu_df.to_parquet(mu_pk_file, index=False)\n",
    "print(f\"Saved MU.parquet with {len(mu_df)} rows.\")\n",
    "del mu_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322fb675",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Processing IN.txt...\")\n",
    "in_df = pd.read_csv(in_file, header=None, names=col_headers, sep='\\\\t')\n",
    "in_df.to_parquet(in_pk_file, index=False)\n",
    "print(f\"Saved IN.parquet with {len(in_df)} rows.\")\n",
    "del in_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782ff05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Processing EP.txt...\")\n",
    "ep_df = pd.read_csv(ep_file, header=None, names=col_headers, sep='\\\\t')\n",
    "ep_df.to_parquet(ep_pk_file, index=False)\n",
    "print(f\"Saved EP.parquet with {len(ep_df)} rows.\")\n",
    "del ep_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f0f6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n### Data ingestion is complete. ###\")\n",
    "print(\"All raw data has been converted to Parquet format in the 'Data/parquets' directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6603f5c",
   "metadata": {},
   "source": [
    "### With above steps we have injested data from external data sources and converted them to common format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cd7aa5",
   "metadata": {},
   "source": [
    "## Minimum Sample required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ee7169",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_total_sample_size_anova_power(\n",
    "    num_classes: int,\n",
    "    effect_size_f: float = 0.25,  # Cohen's f for ANOVA\n",
    "    alpha: float = 0.05,\n",
    "    power: float = 0.80\n",
    ") -> int:\n",
    "    \"\"\"\n",
    "    Calculates the total sample size required for a multi-class comparison (ANOVA-like)\n",
    "    to detect a given effect size with specified power and significance.\n",
    "\n",
    "    This helps ensure that there's enough data to detect meaningful differences\n",
    "    in feature distributions across classes.\n",
    "\n",
    "    Args:\n",
    "        num_classes (int): The number of distinct classes (groups).\n",
    "        effect_size_f (float): Cohen's f effect size.\n",
    "                               - 0.1: small effect\n",
    "                               - 0.25: medium effect (default)\n",
    "                               - 0.4: large effect\n",
    "        alpha (float): Significance level (Type I error rate), e.g., 0.05.\n",
    "        power (float): Desired statistical power (1 - Type II error rate), e.g., 0.80.\n",
    "\n",
    "    Returns:\n",
    "        int: The total estimated sample size.\n",
    "    \"\"\"\n",
    "    if num_classes <= 1:\n",
    "        raise ValueError(\"Number of classes must be greater than 1 for comparison.\")\n",
    "    if not (0 < alpha < 1) or not (0 < power < 1):\n",
    "        raise ValueError(\"Alpha and power must be between 0 and 1.\")\n",
    "    if effect_size_f <= 0:\n",
    "        raise ValueError(\"Effect size must be positive.\")\n",
    "\n",
    "    # Create a power analysis object for F-tests (ANOVA)\n",
    "    power_calculator = FTestAnovaPower()\n",
    "\n",
    "    # Calculate the number of observations (samples) per group (class)\n",
    "    # k_groups is the number of classes\n",
    "    # nobs is the number of observations per group\n",
    "    nobs_per_group = power_calculator.solve_power(\n",
    "        effect_size=effect_size_f,\n",
    "        nobs=None,\n",
    "        alpha=alpha,\n",
    "        power=power,\n",
    "        k_groups=num_classes\n",
    "    )\n",
    "\n",
    "    total_samples = int(np.ceil(nobs_per_group * num_classes))\n",
    "\n",
    "    print(f\"ANOVA Power Analysis: To detect an effect size (Cohen's f) of {effect_size_f} \")\n",
    "    print(f\"  across {num_classes} classes with alpha={alpha} and power={power}:\")\n",
    "    print(f\"  - Samples needed per class: {int(np.ceil(nobs_per_group))}\")\n",
    "    print(f\"  - Total estimated sample size: {total_samples}\")\n",
    "    return total_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb131ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_samples_anova = calculate_total_sample_size_anova_power(num_classes=10, effect_size_f=0.25, alpha=0.05, power=0.80)\n",
    "total_samples_anova_large_effect = calculate_total_sample_size_anova_power(num_classes=10, effect_size_f=0.4, alpha=0.05, power=0.90)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WalshCapstone (3.11.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
