{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7148f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Importing Libraries\n",
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import json\n",
    "import traceback\n",
    "import joblib\n",
    "\n",
    "# Machine Learning imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization, Activation\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfa30d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb799e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join('/mnt', 'd', 'work', 'Walsh', 'Capstone', 'Published', 'Data')\n",
    "prk_folder = os.path.join(data_dir, 'parquets')\n",
    "models_folder = os.path.join(data_dir, 'models')\n",
    "\n",
    "# Global variables\n",
    "SAMPLING_RATES = {\n",
    "    \"MW\": 512, \"EP\": 128, \"MU\": 220, \"IN\": 128,\n",
    "    \"EP22_Train\": 128, \"EP22_Test\": 128\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02adad53",
   "metadata": {},
   "outputs": [],
   "source": [
    "MU_file = os.path.join(prk_folder, 'MU.parquet')\n",
    "MU_Process_file = os.path.join(prk_folder, 'MU_Processed.parquet')\n",
    "MU_Features_file = os.path.join(prk_folder, 'MU_Features.parquet')\n",
    "MU_Process_Agg_file = os.path.join(prk_folder, 'MU_processed_aggregated.parquet')\n",
    "\n",
    "EP_file = os.path.join(prk_folder, 'EP.parquet')\n",
    "EP_Process_file = os.path.join(prk_folder, 'EP_Processed.parquet')\n",
    "EP_Features_file = os.path.join(prk_folder, 'EP_Features.parquet')\n",
    "EP_Process_Agg_file = os.path.join(prk_folder, 'EP_processed_aggregated.parquet')\n",
    "\n",
    "MW_file = os.path.join(prk_folder, 'MW.parquet')\n",
    "MW_Process_file = os.path.join(prk_folder, 'MW_Processed.parquet')\n",
    "MW_Features_file = os.path.join(prk_folder, 'MW_Features.parquet')\n",
    "MW_Process_Agg_file = os.path.join(prk_folder, 'MW_processed_aggregated.parquet')\n",
    "\n",
    "IN_file = os.path.join(prk_folder, 'IN.parquet')\n",
    "IN_Process_file = os.path.join(prk_folder, 'IN_Processed.parquet')\n",
    "IN_Features_file = os.path.join(prk_folder, 'IN_Features.parquet')\n",
    "IN_Process_Agg_file = os.path.join(prk_folder, 'IN_processed_aggregated.parquet')\n",
    "\n",
    "EP22_Train_file = os.path.join(prk_folder, 'EP22_Train.parquet')\n",
    "EP22_Train_Process_file = os.path.join(prk_folder, 'EP22_Train_Processed.parquet')\n",
    "EP22_Train_Features_file = os.path.join(prk_folder, 'EP22_Train_Features.parquet')\n",
    "EP22_Train_Process_Agg_file = os.path.join(prk_folder, 'EP22_Train_processed_aggregated.parquet')\n",
    "\n",
    "EP22_Test_file = os.path.join(prk_folder, 'EP22_Test.parquet')\n",
    "EP22_Test_Process_file = os.path.join(prk_folder, 'EP22_Test_Processed.parquet')\n",
    "EP22_Test_Features_file = os.path.join(prk_folder, 'EP22_Test_Features.parquet')\n",
    "EP22_Test_Process_Agg_file = os.path.join(prk_folder, 'EP22_Test_processed_aggregated.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1d06b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_data(df, interested_col = 'data'):\n",
    "\n",
    "    new_row = {}\n",
    "    tmp = {}\n",
    "    try:\n",
    "        tmp_gpr_df = df.groupby(['device', 'event'])\n",
    "        if interested_col in df.columns:\n",
    "            if interested_col != 'data':\n",
    "                df.columns = df.columns.str.replace(interested_col, 'data')\n",
    "            for grp in tmp_gpr_df:\n",
    "                tmp = {}\n",
    "                if grp[1][\"event\"].empty:\n",
    "                    continue\n",
    "                for index, row in grp[1].iterrows():\n",
    "                    tmp[row['channel']] = row['data']\n",
    "                \n",
    "                tmp[\"code\"] = int(grp[1][\"code\"].values[0])\n",
    "                new_row[int(grp[1][\"event\"].values[0])] = tmp\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing group: {e}\")\n",
    "        print(traceback.format_exc())\n",
    "\n",
    "    result_df = pd.DataFrame.from_dict(new_row, orient='index')\n",
    "    result_df.reset_index(inplace=True)\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a7b379",
   "metadata": {},
   "outputs": [],
   "source": [
    "mw_process_df = pd.read_parquet(MW_Process_file)\n",
    "mw_agg_df = aggregate_data(mw_process_df, 'processed_signal')\n",
    "mw_agg_df.to_parquet(MW_Process_Agg_file, index=False)\n",
    "mw_process_df = None\n",
    "mw_agg_df = None\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fa0573",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_process_df = pd.read_parquet(MU_Process_file)\n",
    "mu_agg_df = aggregate_data(mu_process_df, 'processed_signal')\n",
    "mu_agg_df.to_parquet(MU_Process_Agg_file, index=False)\n",
    "mu_process_df = None\n",
    "mu_agg_df = None\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5ab132",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_process_df = pd.read_parquet(IN_Process_file)\n",
    "in_agg_df = aggregate_data(in_process_df, 'processed_signal')\n",
    "in_agg_df.to_parquet(IN_Process_Agg_file, index=False)\n",
    "in_process_df = None\n",
    "in_agg_df = None\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb659e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ep_process_df = pd.read_parquet(EP_Process_file)\n",
    "ep_agg_df = aggregate_data(ep_process_df, 'processed_signal')\n",
    "ep_agg_df.to_parquet(IN_Process_Agg_file, index=False)\n",
    "ep_process_df = None\n",
    "ep_agg_df = None\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933c3d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_column_for_training(processed_df: pd.DataFrame, col_name: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Converts the specified column (time-series data) into a feature matrix.\n",
    "    Each time point in the signal becomes a separate feature.\n",
    "    \"\"\"\n",
    "    if col_name not in processed_df.columns or 'code' not in processed_df.columns:\n",
    "        logging.error(f\"Input DataFrame must contain '{col_name}' and 'code' columns.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Removing Noise signals\n",
    "    processed_df = processed_df[processed_df[\"code\"] != -1]\n",
    "\n",
    "    # More robust filter that works for both lists and ndarrays.\n",
    "    df = processed_df[processed_df[col_name].apply(lambda x: hasattr(x, '__len__') and len(x) > 0)].copy()\n",
    "\n",
    "    if df.empty:\n",
    "        logging.warning(\"No valid signals found in the processed DataFrame to prepare for training.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Use np.vstack for robust creation of the feature matrix from lists or arrays.\n",
    "    signal_matrix = np.vstack(df[col_name].values)\n",
    "    \n",
    "    # Create new column names for each time point (feature)\n",
    "    feature_names = [f'data_point_{i}' for i in range(signal_matrix.shape[1])]\n",
    "    \n",
    "    # Create a new DataFrame for the features\n",
    "    features_df = pd.DataFrame(signal_matrix, columns=feature_names, index=df.index)\n",
    "    \n",
    "    # Combine the new features DataFrame with the essential 'code' column from the original df\n",
    "    model_ready_df = pd.concat([df[['code']], features_df], axis=1)\n",
    "    \n",
    "    return model_ready_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90634ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def prepare_single_channelfor_training1(df, label_col='code', test_size=0.2, random_state=42):\n",
    "#     feature_cols = [col for col in df.columns if col.startswith('data_point_')]\n",
    "    \n",
    "#     if not feature_cols:\n",
    "#         logging.error(\"No feature columns (starting with 'data_point_') found in the DataFrame for training.\")\n",
    "#         return None, np.array([]), np.array([]), np.array([]), np.array([])\n",
    "\n",
    "#     X = df[feature_cols].copy().fillna(0)\n",
    "#     y = df[label_col].copy()\n",
    "    \n",
    "#     if X.empty or y.empty:\n",
    "#         logging.error(\"Feature matrix (X) or label vector (y) is empty.\")\n",
    "#         return None, np.array([]), np.array([]), np.array([]), np.array([])\n",
    "\n",
    "#     scaler = StandardScaler()\n",
    "#     X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "#     if len(np.unique(y)) > 1:\n",
    "#         X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y)\n",
    "#         X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, stratify=y_test)\n",
    "#         return scaler, X_train, y_train, X_val, y_val, X_test, y_test\n",
    "#     else:\n",
    "#         logging.warning(\"Only one class present in data. Cannot perform stratified split.\")\n",
    "#         X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "#         X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, stratify=y_test)\n",
    "#         return scaler, X_train, y_train, X_val, y_val, X_test, y_test\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e92d98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_single_channel_for_training(df, label_col='code', col_name = None, test_size=0.2, random_state=42):\n",
    "    df = df[df['code'] != -1]  # Removing Noise signals\n",
    "\n",
    "    if \"index\" in df.columns:\n",
    "        df = df.drop(columns=[\"index\"])\n",
    "\n",
    "    id_vars = ['code']\n",
    "\n",
    "    if col_name == 'None' or col_name not in df.columns:\n",
    "        logging.error(f\"Column name for signal data is not provided or does not exist in DataFrame.\")\n",
    "        return None, np.array([]), np.array([]), np.array([]), np.array([])\n",
    "    \n",
    "    if label_col not in df.columns:\n",
    "        logging.error(f\"Label column '{label_col}' does not exist in DataFrame.\")\n",
    "        return None, np.array([]), np.array([]), np.array([]), np.array([])\n",
    "    \n",
    "    # All other columns are assumed to be the channel data columns.\n",
    "    channel_cols = [col_name]\n",
    "\n",
    "    concatenated_arrays = df[channel_cols].apply(\n",
    "        lambda row: np.concatenate(row.values), axis=1\n",
    "    )\n",
    "\n",
    "    expanded_df = pd.DataFrame(\n",
    "        concatenated_arrays.to_list(),\n",
    "        index=df.index\n",
    "    )\n",
    "    \n",
    "    # Convert all column names to string format\n",
    "    expanded_df.columns = [str(col) for col in expanded_df.columns]\n",
    "    complete_df = pd.concat([df[id_vars], expanded_df], axis=1)\n",
    "\n",
    "    if complete_df.empty:\n",
    "        logging.error(\"No feature columns ( found in the DataFrame for training.\")\n",
    "        return None, np.array([]), np.array([]), np.array([]), np.array([]), np.array([]), np.array([])\n",
    "\n",
    "    X = complete_df\n",
    "    y = df[label_col].copy()\n",
    "    \n",
    "    if X.empty or y.empty:\n",
    "        logging.error(\"Feature matrix (X) or label vector (y) is empty.\")\n",
    "        return None, np.array([]), np.array([]), np.array([]), np.array([]), np.array([]), np.array([])\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    if len(np.unique(y)) > 1:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y)\n",
    "        X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, stratify=y_test)\n",
    "        return scaler, X_train, y_train, X_val, y_val, X_test, y_test\n",
    "    else:\n",
    "        logging.warning(\"Only one class present in data. Cannot perform stratified split.\")\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "        X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, stratify=y_test)\n",
    "        return scaler, X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a106934",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_multi_channelfor_training(df, label_col='code', test_size=0.2, random_state=42):\n",
    "\n",
    "    df = df[df['code'] != -1]  # Removing Noise signals\n",
    "\n",
    "    # 'index' and 'code' are the identifier columns.\n",
    "    id_vars = ['index', 'code']\n",
    "\n",
    "\n",
    "    # All other columns are assumed to be the channel data columns.\n",
    "    channel_cols = [col for col in df.columns if col not in id_vars]\n",
    "\n",
    "    concatenated_arrays = df[channel_cols].apply(\n",
    "        lambda row: np.concatenate(row.values), axis=1\n",
    "    )\n",
    "\n",
    "    expanded_df = pd.DataFrame(\n",
    "        concatenated_arrays.to_list(),\n",
    "        index=df.index\n",
    "    )\n",
    "    \n",
    "    # Convert all column names to string format\n",
    "    expanded_df.columns = [str(col) for col in expanded_df.columns]\n",
    "    complete_df = pd.concat([df[id_vars], expanded_df], axis=1)\n",
    "\n",
    "    if \"index\" in complete_df.columns:\n",
    "        complete_df = complete_df.drop(columns=[\"index\"])\n",
    "\n",
    "\n",
    "    # print(f\"Complete DataFrame shape: {complete_df.shape}\")\n",
    "    # print(f\"Complete DataFrame columns: {complete_df.columns.tolist()}\")\n",
    "    if complete_df.empty:\n",
    "        logging.error(\"No feature columns (starting with 'data_point_') found in the DataFrame for training.\")\n",
    "        return None, np.array([]), np.array([]), np.array([]), np.array([])\n",
    "\n",
    "    X = complete_df\n",
    "    y = df[label_col].copy()\n",
    "    \n",
    "    if X.empty or y.empty:\n",
    "        logging.error(\"Feature matrix (X) or label vector (y) is empty.\")\n",
    "        return None, np.array([]), np.array([]), np.array([]), np.array([])\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    if len(np.unique(y)) > 1:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y)\n",
    "        X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, stratify=y_test)\n",
    "        return scaler, X_train, y_train, X_val, y_val, X_test, y_test\n",
    "    else:\n",
    "        logging.warning(\"Only one class present in data. Cannot perform stratified split.\")\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "        X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, stratify=y_test)\n",
    "        return scaler, X_train, y_train, X_val, y_val, X_test, y_test\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c2f9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c186e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mw_agg_df = pd.read_parquet(MW_Process_Agg_file)\n",
    "mu_agg_df = pd.read_parquet(MU_Process_Agg_file)\n",
    "in_agg_df = pd.read_parquet(IN_Process_Agg_file)\n",
    "ep_agg_df = pd.read_parquet(EP_Process_Agg_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5ce7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler, X_train, y_train, X_val, y_val, X_test, y_test = prepare_multi_channelfor_training(mu_agg_df)\n",
    "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "print(f\"X_val shape: {X_val.shape}, y_val shape: {y_val.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bc305f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e3db5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_model_df = prepare_column_for_training(mu_agg_df, 'FP2')\n",
    "mu_model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4778ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7065f832",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_RandomForest_model(X_train, y_train, X_val, y_val, X_test, y_test,  Data_name: str, Model_name : str, n_estimators=100, max_depth=None, random_state=42):\n",
    "    print(\"Training Random Forest Classifier...\")\n",
    "    \n",
    "    model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=random_state)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Validation\n",
    "    y_val_pred = model.predict(X_test)\n",
    "    val_accuracy = accuracy_score(y_test, y_val_pred)\n",
    "\n",
    "    val_f1 = f1_score(y_test, y_val_pred, average='weighted')\n",
    "\n",
    "    report = classification_report(y_test, y_val_pred, zero_division=0)\n",
    "\n",
    "    print(f\"Validation Accuracy: {val_accuracy:.4f}, F1 Score: {val_f1:.4f}\")\n",
    "\n",
    "    # Save model\n",
    "    model_path = os.path.join(models_folder, f\"{Data_name}_{Model_name}_RF_model.joblib\")\n",
    "    joblib.dump(model, model_path)\n",
    "    print(f\"Model saved to {model_path}\")\n",
    "    \n",
    "    # Save Accuracy and Report\n",
    "    acc_report_path = os.path.join(models_folder, f\"{Data_name}_{Model_name}_RF_report.txt\")\n",
    "    with open(acc_report_path, 'w') as f:\n",
    "        f.write(f\"Test Accuracy: {val_accuracy:.4f}\\n\")\n",
    "        f.write(f\"Classification Report:\\n{report}\\n\")\n",
    "    \n",
    "    return model, val_accuracy, val_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b033e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BasicSingleChannelCNN(n_timesteps, n_features, n_outputs):\n",
    "    model = Sequential([\n",
    "        Conv1D(filters=64, kernel_size=5, activation='relu', input_shape=(n_features, n_timesteps)),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Dropout(0.5),\n",
    "        Conv1D(filters=64, kernel_size=5, activation='relu'),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Dropout(0.5),\n",
    "        Flatten(),\n",
    "        Dense(100, activation='relu'),\n",
    "        Dense(n_outputs, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2f660d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BasicSingleChannelCNN(256, 2214, 10)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cceadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_layers = model.layers\n",
    "\n",
    "for layer in m_layers:\n",
    "    print(f\"Layer: {layer.name}, {type(layer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3f4c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_single_channel_dnn_models(X_train, y_train, X_val, y_val, X_test, y_test, \n",
    "                        Data_name: str, Model_name : str, \n",
    "                        num_classes=10, models_folder=models_folder):\n",
    "    \"\"\"Train and evaluate selected deep model.\n",
    "    Expects X_* as (samples, features) for BasicDNN and (samples, n_features, n_timesteps) for CNN models.\n",
    "    y_* are integer class labels.\n",
    "    \"\"\"\n",
    "    if X_train is None or getattr(X_train, 'size', 0) == 0:\n",
    "        print(\"--- DNN ---\\nSkipping training: No data available.\")\n",
    "        return None, 0, \"\"\n",
    "\n",
    "    # Ensure numpy arrays\n",
    "    X_train = np.asarray(X_train)\n",
    "    X_val = np.asarray(X_val)\n",
    "    X_test = np.asarray(X_test)\n",
    "    y_train = np.asarray(y_train)\n",
    "    y_val = np.asarray(y_val)\n",
    "    y_test = np.asarray(y_test)\n",
    "\n",
    "    n_classes = int(max(y_train.max(), y_val.max(), y_test.max()) + 1)\n",
    "\n",
    "    # One-hot encode labels\n",
    "    y_train_cat = tf.keras.utils.to_categorical(y_train, num_classes=n_classes)\n",
    "    y_val_cat = tf.keras.utils.to_categorical(y_val, num_classes=n_classes)\n",
    "    y_test_cat = tf.keras.utils.to_categorical(y_test, num_classes=n_classes)\n",
    "\n",
    "    # Determine input dimensions\n",
    "    is_cnn = Model_name in ['BasicSingleChannelCNN']\n",
    "\n",
    "    if is_cnn:\n",
    "        # Expect raw shape (samples, features); reshape to (samples, n_features, 1) treating each feature as timestep\n",
    "        if X_train.ndim == 2:\n",
    "            X_train_c = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "            X_val_c = X_val.reshape((X_val.shape[0], X_val.shape[1], 1))\n",
    "            X_test_c = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "        else:\n",
    "            X_train_c, X_val_c, X_test_c = X_train, X_val, X_test\n",
    "        n_features, n_timesteps = X_train_c.shape[1], X_train_c.shape[2]\n",
    "    else:\n",
    "        n_features = X_train.shape[1]\n",
    "        n_timesteps = 1  # placeholder\n",
    "\n",
    "    # Select model\n",
    "    if Model_name == 'BasicSingleChannelCNN':\n",
    "        model = BasicSingleChannelCNN(n_timesteps=n_timesteps, n_features=n_features, n_outputs=n_classes)\n",
    "    # elif Model_name == 'OneD_CNN_CausalDilated':\n",
    "    #     model = OneD_CNN_CausalDilated(n_timesteps=n_timesteps, n_features=n_features, n_outputs=n_classes)\n",
    "    else:\n",
    "        print(f\"Model {Model_name} not recognized.\")\n",
    "        return None, 0, \"\"\n",
    "\n",
    "    # model.summary()\n",
    "\n",
    "    # Callbacks\n",
    "    callback_es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "    callback_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5)\n",
    "\n",
    "    os.makedirs(models_folder, exist_ok=True)\n",
    "    checkpointPath = os.path.join(models_folder, f\"{Data_name}_best_{Model_name}_weights.keras\")\n",
    "    checkpointer = ModelCheckpoint(filepath=checkpointPath, verbose=0, save_best_only=True, monitor='val_loss')\n",
    "\n",
    "    epochs, batch_size = 200, 128\n",
    "\n",
    "    if is_cnn:\n",
    "        history = model.fit(X_train_c, y_train_cat, epochs=epochs, batch_size=batch_size, verbose=0,\n",
    "                            validation_data=(X_val_c, y_val_cat), callbacks=[callback_es, callback_lr, checkpointer])\n",
    "        eval_inputs = X_test_c\n",
    "    else:\n",
    "        history = model.fit(X_train, y_train_cat, epochs=epochs, batch_size=batch_size, verbose=0,\n",
    "                            validation_data=(X_val, y_val_cat), callbacks=[callback_es, callback_lr, checkpointer])\n",
    "        eval_inputs = X_test\n",
    "\n",
    "    loss, accuracy = model.evaluate(eval_inputs, y_test_cat, batch_size=batch_size, verbose=0)\n",
    "    y_pred_prob = model.predict(eval_inputs, batch_size=batch_size, verbose=0)\n",
    "    y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "    report = classification_report(y_test, y_pred, zero_division=0)\n",
    "    # print(f\"Test Accuracy: {accuracy:.4f}\\nClassification Report:\\n{report}\")\n",
    "\n",
    "    # Save model\n",
    "    model_save_path = os.path.join(models_folder, f\"{Data_name}_{Model_name}_CNN.keras\")\n",
    "    model.save(model_save_path)\n",
    "\n",
    "    # Save Accuracy and Report\n",
    "    acc_report_path = os.path.join(models_folder, f\"{Data_name}_{Model_name}_CNN_report.txt\")\n",
    "    with open(acc_report_path, 'w') as f:\n",
    "        f.write(f\"Test Accuracy: {accuracy:.4f}\\n\")\n",
    "        f.write(f\"Classification Report:\\n{report}\\n\")\n",
    "\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    val_accuracy = accuracy_score(y_test, y_pred)\n",
    "    val_f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    return model, val_accuracy, val_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b435a235",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8876aa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae58713a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_model_df = prepare_column_for_training(mw_agg_df, 'FP1')\n",
    "scaler, X_train, y_train, X_val, y_val, X_test, y_test = prepare_for_training(mu_model_df)\n",
    "print(X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acf40c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, val_accuracy, val_f1 = evaluate_dnn_models(\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test,\n",
    "    Data_name='MW_FP1', Model_name='BasicCNN'\n",
    ")\n",
    "print('Final Accuracy:', val_accuracy, 'Final F1:', val_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20542e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, val_accuracy, val_f1 = evaluate_dnn_models(\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test,\n",
    "    Data_name='MW_FP1', Model_name='OneD_CNN_CausalDilated'\n",
    ")\n",
    "print('Final Accuracy:', val_accuracy, 'Final F1:', val_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef6a849",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_model_df = prepare_column_for_training(mu_agg_df, 'FP2')\n",
    "scaler, X_train, y_train, X_val, y_val, X_test, y_test = prepare_for_training(mu_model_df)\n",
    "print(X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape)\n",
    "model, val_accuracy, val_f1 = evaluate_dnn_models(\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test,\n",
    "    Data_name='MU_FP2', Model_name='BasicCNN'\n",
    ")\n",
    "print('Final Accuracy:', val_accuracy, 'Final F1:', val_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495909ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, val_accuracy, val_f1 = evaluate_dnn_models(\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test,\n",
    "    Data_name='MU_FP2', Model_name='OneD_CNN_CausalDilated'\n",
    ")\n",
    "print('Final Accuracy:', val_accuracy, 'Final F1:', val_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef821417",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = []\n",
    "for device, channels in results.items():\n",
    "    for channel, models in channels.items():\n",
    "        results_df.append({\n",
    "                \"Device\": device,\n",
    "                \"Channel\": channel,\n",
    "                \"RF_ACC\" : models[\"RandomForest\"][\"acc\"],\n",
    "                \"CNN_ACC\" : models[\"BasicSingleChannelCNN\"][\"acc\"],\n",
    "                \"RF_F1\" : models[\"RandomForest\"][\"f1\"],\n",
    "                \"CNN_F1\" : models[\"BasicSingleChannelCNN\"][\"f1\"]\n",
    "            })\n",
    "\n",
    "results_df = pd.DataFrame(results_df)\n",
    "results_df = results_df.sort_values(by=[\"Device\", \"Channel\"]).reset_index(drop=True)\n",
    "results_df.to_csv(os.path.join(models_folder, 'model_results_summary.csv'), index=False)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e9a810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mw_agg_df = pd.read_parquet(MW_Process_Agg_file)\n",
    "# mu_agg_df = pd.read_parquet(MU_Process_Agg_file)\n",
    "# in_agg_df = pd.read_parquet(IN_Process_Agg_file)\n",
    "# ep_agg_df = pd.read_parquet(EP_Process_Agg_file)\n",
    "\n",
    "processed_aggs = {\n",
    "    \"MW\" : mw_agg_df,\n",
    "    \"MU\" : mu_agg_df,\n",
    "    \"IN\" : in_agg_df,\n",
    "    \"EP\" : ep_agg_df\n",
    "}\n",
    "\n",
    "results_full = {\n",
    "    \"MW\": {},\n",
    "    \"MU\": {},\n",
    "    \"IN\": {},\n",
    "    \"EP\": {}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79160195",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in processed_aggs.keys():\n",
    "    print(f\"Processing {key} data...\")\n",
    "    df = processed_aggs[key]\n",
    "\n",
    "    scaler, X_train, y_train, X_val, y_val, X_test, y_test = prepare_multi_channelfor_training(df)\n",
    "    print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "    print(f\"X_val shape: {X_val.shape}, y_val shape: {y_val.shape}\")\n",
    "    print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n",
    "\n",
    "    model_rf, rf_val_accuracy, rf_val_f1 = evaluate_RandomForest_model(\n",
    "        X_train, y_train, X_val, y_val, X_test, y_test,\n",
    "        Data_name=f'{key}_Full', Model_name='RandomForest'\n",
    "    )\n",
    "\n",
    "    model_cnn, cnn_val_accuracy, cnn_val_f1 = evaluate_single_channel_dnn_models(\n",
    "        X_train, y_train, X_val, y_val, X_test, y_test,\n",
    "        Data_name=f'{key}_Full', Model_name='BasicSingleChannelCNN'\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    results_full[key] = {}\n",
    "    results_full[key][\"RandomForest\"] = {\"acc\": rf_val_accuracy, \"f1\": rf_val_f1}\n",
    "    results_full[key][\"BasicSingleChannelCNN\"] = {\"acc\": cnn_val_accuracy, \"f1\": cnn_val_f1}\n",
    "results_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1457cdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_full_data = []\n",
    "for key in results_full.keys():\n",
    "    print(f\"Results for {key}:\")\n",
    "    results_full_data.append({\n",
    "            \"Device\" : key,\n",
    "            \"RF_acc\" : results_full[key][\"RandomForest\"][\"acc\"],\n",
    "            \"RF_f1\" : results_full[key][\"RandomForest\"][\"f1\"],\n",
    "            \"CNN_acc\" : results_full[key][\"BasicSingleChannelCNN\"][\"acc\"],\n",
    "            \"CNN_f1\" : results_full[key][\"BasicSingleChannelCNN\"][\"f1\"]\n",
    "        })\n",
    "results_full_data = pd.DataFrame(results_full_data)\n",
    "results_full_data.to_csv(os.path.join(models_folder, 'full_model_results_summary.csv'), index=False)\n",
    "results_full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45180f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_full_data = pd.read_csv(os.path.join(models_folder, 'full_model_results_summary.csv'))\n",
    "results_full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90055575",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbc26de",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_col = {}\n",
    "scaler, X_train, y_train, X_val, y_val, X_test, y_test = None, None, None, None, None, None, None\n",
    "for key in processed_aggs.keys():\n",
    "    df = processed_aggs[key]\n",
    "    results_col[key] = {}\n",
    "    for col in df.columns:\n",
    "        \n",
    "        if col == 'index' or col == 'code':\n",
    "            continue\n",
    "\n",
    "        results_col[key][col] = {}\n",
    "\n",
    "        # print(key, col)\n",
    "        # col_df = prepare_column_for_training(df, col)\n",
    "        # print(f\"Prepared DataFrame for {key} - {col}: {col_df.shape}\")\n",
    "        scaler, X_train, y_train, X_val, y_val, X_test, y_test = prepare_single_channel_for_training(df, col_name=col)\n",
    "        print(f\"Train/Test split for {key} - {col}:\")\n",
    "        print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "        print(f\"X_val shape: {X_val.shape}, y_val shape: {y_val.shape}\")\n",
    "\n",
    "        model_rf, rf_val_accuracy, rf_val_f1 = evaluate_RandomForest_model(\n",
    "            X_train, y_train, X_val, y_val, X_test, y_test,\n",
    "            Data_name=f'{key}_{col}', Model_name='RandomForest'\n",
    "        )\n",
    "\n",
    "        model_cnn, cnn_val_accuracy, cnn_val_f1 = evaluate_single_channel_dnn_models(\n",
    "            X_train, y_train, X_val, y_val, X_test, y_test,\n",
    "            Data_name=f'{key}_{col}', Model_name='BasicSingleChannelCNN'\n",
    "        )\n",
    "        results_col[key][col] = {\n",
    "            \"RandomForest\": {\"acc\": rf_val_accuracy, \"f1\": rf_val_f1},\n",
    "            \"BasicSingleChannelCNN\": {\"acc\": cnn_val_accuracy, \"f1\": cnn_val_f1}\n",
    "        }\n",
    "\n",
    "        with open(os.path.join(models_folder, 'latest_model_results.json'), 'w') as f:\n",
    "            json.dump(results_col, f, indent=4)\n",
    "\n",
    "results_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216fbd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f87b244",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_col_data = []\n",
    "\n",
    "for key in results_col.keys():\n",
    "    # print(f\"Results for {key}:\")\n",
    "    for col in results_col[key].keys():\n",
    "        # print(f\" Channel: {col}\")\n",
    "        # print(f\"  RandomForest - Acc: {results_col[key][col]['RandomForest']['acc']}, F1: {results_col[key][col]['RandomForest']['f1']}\")\n",
    "        # print(f\"  BasicSingleChannelCNN - Acc: {results_col[key][col]['BasicSingleChannelCNN']['acc']}, F1: {results_col[key][col]['BasicSingleChannelCNN']['f1']}\")\n",
    "        results_col_data.append({\n",
    "            \"Device\" : key,\n",
    "            \"Channel\" : col,\n",
    "            \"RF_acc\" : results_col[key][col][\"RandomForest\"][\"acc\"],\n",
    "            \"CNN_acc\" : results_col[key][col][\"BasicSingleChannelCNN\"][\"acc\"],\n",
    "            \"RF_f1\" : results_col[key][col][\"RandomForest\"][\"f1\"],\n",
    "            \"CNN_f1\" : results_col[key][col][\"BasicSingleChannelCNN\"][\"f1\"]\n",
    "        })\n",
    "results_col_data = pd.DataFrame(results_col_data)\n",
    "results_col_data.sort_values(by=[\"Device\", \"Channel\"]).reset_index(drop=True)\n",
    "results_col_data.to_csv(os.path.join(models_folder, 'channel_model_results_summary.csv'), index=False)\n",
    "results_col_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbfa1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_col_data.aggregate({'RF_acc': ['mean'], 'CNN_acc': ['mean']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee41c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "MU_file = os.path.join(prk_folder, 'MU.parquet')\n",
    "IN_file = os.path.join(prk_folder, 'IN.parquet')\n",
    "EP_file = os.path.join(prk_folder, 'EP.parquet')\n",
    "MW_file = os.path.join(prk_folder, 'MW.parquet')\n",
    "\n",
    "mw_df = pd.read_parquet(MW_file)\n",
    "in_df = pd.read_parquet(IN_file)\n",
    "ep_df = pd.read_parquet(EP_file)\n",
    "mu_df = pd.read_parquet(MU_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eff5ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_samples = (mw_df.shape[0] + in_df.shape[0] +  ep_df.shape[0] + mu_df.shape[0]) * 2\n",
    "total_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a7327c",
   "metadata": {},
   "outputs": [],
   "source": [
    "((results_col_data[\"RF_acc\"].mean() + results_col_data[\"CNN_acc\"].mean() ) / 2) * total_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7456336",
   "metadata": {},
   "outputs": [],
   "source": [
    "(results_col_data[\"RF_acc\"].mean() + results_col_data[\"CNN_acc\"].mean())  * total_samples / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8e41ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ML Model Output ---\n",
    "total_samples = (mw_df.shape[0] + in_df.shape[0] +  ep_df.shape[0] + mu_df.shape[0]) * 2\n",
    "# correct_predictions =  ((results_col_data[\"RF_acc\"].mean() + results_col_data[\"CNN_acc\"].mean() ) / 2) * total_samples  # Number of successes (count)\n",
    "# total_samples = results_col_data.shape[0] * 2          # Total trials (nobs)\n",
    "chance_baseline = 0.10        # H0: Accuracy <= 10%\n",
    "correct_predictions = 0.56321 * total_samples  # Number of successes (count)\n",
    "# --- Perform the Z-Test ---\n",
    "# We test if our model's accuracy is 'larger' than the baseline.\n",
    "z_stat, p_value = proportions_ztest(count=correct_predictions, nobs=total_samples, value=chance_baseline, alternative='larger')\n",
    "\n",
    "# --- Interpret the Results ---\n",
    "model_accuracy = correct_predictions / total_samples\n",
    "# model_accuracy = 56\n",
    "print(f\"Model Accuracy: {model_accuracy:.4f}\")\n",
    "print(f\"Z-statistic: {z_stat:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "\n",
    "alpha = 0.05  # Significance level\n",
    "if p_value < alpha:\n",
    "    print(\"\\n✅ Result: Reject the null hypothesis.\")\n",
    "    print(\"Conclusion: The model's accuracy is significantly greater than the 10% chance baseline.\")\n",
    "else:\n",
    "    print(\"\\n❌ Result: Fail to reject the null hypothesis.\")\n",
    "    print(\"Conclusion: There is not enough evidence to say the model performs better than chance.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bee8e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f829c692",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = prepare_single_channelfor_training(mu_agg_df, col_name='FP2')\n",
    "tmp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6550c43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_10_crossfold_cnn(df, device = None):\n",
    "    label_col = 'code'\n",
    "    n_classes = 10\n",
    "    df = df[df[label_col] != -1]  # Removing Noise signals\n",
    "\n",
    "    # 'index' and 'code' are the identifier columns.\n",
    "    id_vars = ['index', label_col]\n",
    "\n",
    "    epochs, batch_size = 200, 128\n",
    "\n",
    "    MW_Model_file = os.path.join(models_folder, 'MW_Full_BasicSingleChannelCNN_CNN.keras')\n",
    "    MU_Model_file = os.path.join(models_folder, 'MU_Full_best_BasicSingleChannelCNN_weights.keras')\n",
    "    IN_Model_file = os.path.join(models_folder, 'IN_Full_best_BasicSingleChannelCNN_weights.keras')\n",
    "    EP_Model_file = os.path.join(models_folder, 'EP_Full_best_BasicSingleChannelCNN_weights.keras')\n",
    "\n",
    "\n",
    "\n",
    "    models = {\n",
    "        \"MW\": MW_Model_file,\n",
    "        \"MU\": MU_Model_file,\n",
    "        \"IN\": IN_Model_file,\n",
    "        \"EP\": EP_Model_file\n",
    "    }\n",
    "\n",
    "    model = tf.keras.models.load_model(models[device])\n",
    "    # All other columns are assumed to be the channel data columns.\n",
    "    channel_cols = [col for col in df.columns if col not in id_vars]\n",
    "\n",
    "    concatenated_arrays = df[channel_cols].apply(\n",
    "        lambda row: np.concatenate(row.values), axis=1\n",
    "    )\n",
    "\n",
    "    expanded_df = pd.DataFrame(\n",
    "        concatenated_arrays.to_list(),\n",
    "        index=df.index\n",
    "    )\n",
    "    \n",
    "    # Convert all column names to string format\n",
    "    expanded_df.columns = [str(col) for col in expanded_df.columns]\n",
    "    complete_df = pd.concat([df[id_vars], expanded_df], axis=1)\n",
    "\n",
    "    if \"index\" in complete_df.columns:\n",
    "        complete_df = complete_df.drop(columns=[\"index\"])\n",
    "\n",
    "\n",
    "    # print(f\"Complete DataFrame shape: {complete_df.shape}\")\n",
    "    # print(f\"Complete DataFrame columns: {complete_df.columns.tolist()}\")\n",
    "    if complete_df.empty:\n",
    "        logging.error(\"No feature columns (starting with 'data_point_') found in the DataFrame for training.\")\n",
    "        return None, np.array([]), np.array([]), np.array([]), np.array([])\n",
    "\n",
    "    X = complete_df\n",
    "    y = df[label_col].copy()\n",
    "    \n",
    "    if X.empty or y.empty:\n",
    "        logging.error(\"Feature matrix (X) or label vector (y) is empty.\")\n",
    "        return None, np.array([]), np.array([]), np.array([]), np.array([])\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    fold_accuracies = {}\n",
    "    fold_f1_scores = {}\n",
    "\n",
    "    for fold, (train_index, test_index) in enumerate(skf.split(X_scaled, y)):\n",
    "        fold_cnt = fold + 1\n",
    "        fold_accuracies[fold_cnt] = {}\n",
    "        fold_f1_scores[fold_cnt] = {}\n",
    "\n",
    "        X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, stratify=y_test)\n",
    "\n",
    "        model_cnn, cnn_val_accuracy, cnn_val_f1 = evaluate_single_channel_dnn_models(\n",
    "            X_train, y_train, X_val, y_val, X_test, y_test,\n",
    "            Data_name=f'{device}_Fold_{str(fold_cnt)}', Model_name='BasicSingleChannelCNN'\n",
    "        )\n",
    "\n",
    "        # # Reshape for CNN input\n",
    "        # X_train_c = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "        # X_test_c = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "        # y_test_cat = tf.keras.utils.to_categorical(y_test, num_classes=n_classes)\n",
    "\n",
    "        # print(f\"Evaluating model {device} on fold {fold_cnt}...\")\n",
    "        # # Load saved model\n",
    "        # loss, accuracy = model.evaluate(X_test_c, y_test_cat, batch_size=batch_size, verbose=0)\n",
    "        # y_pred_prob = model.predict(X_test_c, batch_size=batch_size, verbose=0)\n",
    "        # y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "        fold_accuracies[fold_cnt][device] = cnn_val_accuracy\n",
    "        fold_f1_scores[fold_cnt][device] = cnn_val_f1\n",
    "\n",
    "\n",
    "    print(f\"Fold Accuracies: {fold_accuracies}\")\n",
    "    print(f\"Fold F1 Scores: {fold_f1_scores}\")\n",
    "    return fold_accuracies, fold_f1_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79b35cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a07900",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_10_fold = {\n",
    "    \"MW\": {},\n",
    "    \"MU\": {},\n",
    "    \"IN\": {},\n",
    "    \"EP\": {}\n",
    "}\n",
    "\n",
    "mu_agg_df = pd.read_parquet(MU_Process_Agg_file)\n",
    "fold_accuracies, fold_f1_scores = evaluate_10_crossfold_cnn(mu_agg_df, device='MU')\n",
    "result_10_fold[\"MU\"][\"Acc\"] = fold_accuracies\n",
    "result_10_fold[\"MU\"][\"F1\"] = fold_f1_scores\n",
    "mw_agg_df = None\n",
    "gc.collect()\n",
    "\n",
    "with open(os.path.join(models_folder, '10_fold_results.json'), 'w') as f:\n",
    "    json.dump(result_10_fold, f, indent=4)\n",
    "\n",
    "mw_agg_df = pd.read_parquet(MW_Process_Agg_file)\n",
    "fold_accuracies, fold_f1_scores = evaluate_10_crossfold_cnn(mw_agg_df, device='MW')\n",
    "result_10_fold[\"MW\"][\"Acc\"] = fold_accuracies\n",
    "result_10_fold[\"MW\"][\"F1\"] = fold_f1_scores\n",
    "mw_agg_df = None\n",
    "gc.collect()\n",
    "\n",
    "with open(os.path.join(models_folder, '10_fold_results.json'), 'w') as f:\n",
    "    json.dump(result_10_fold, f, indent=4)\n",
    "\n",
    "in_agg_df = pd.read_parquet(IN_Process_Agg_file)\n",
    "fold_accuracies, fold_f1_scores = evaluate_10_crossfold_cnn(in_agg_df, device='IN')\n",
    "result_10_fold[\"IN\"][\"Acc\"] = fold_accuracies\n",
    "result_10_fold[\"IN\"][\"F1\"] = fold_f1_scores\n",
    "in_agg_df = None\n",
    "gc.collect()\n",
    "\n",
    "with open(os.path.join(models_folder, '10_fold_results.json'), 'w') as f:\n",
    "    json.dump(result_10_fold, f, indent=4)\n",
    "\n",
    "ep_agg_df = pd.read_parquet(EP_Process_Agg_file)\n",
    "fold_accuracies, fold_f1_scores = evaluate_10_crossfold_cnn(ep_agg_df, device='EP')\n",
    "result_10_fold[\"EP\"][\"Acc\"] = fold_accuracies\n",
    "result_10_fold[\"EP\"][\"F1\"] = fold_f1_scores\n",
    "ep_agg_df = None\n",
    "gc.collect()\n",
    "\n",
    "with open(os.path.join(models_folder, '10_fold_results.json'), 'w') as f:\n",
    "    json.dump(result_10_fold, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36332e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_10_fold_data = []\n",
    "result_10_fold_list = {}\n",
    "for device in result_10_fold.keys():\n",
    "    # print(f\"Device: {device}\")\n",
    "    accs = result_10_fold[device][\"Acc\"]\n",
    "    f1s = result_10_fold[device][\"F1\"]\n",
    "    result_10_fold_list[device] = {\"Acc\": [], \"F1\": []}\n",
    "    for fold in accs.keys():\n",
    "        # print(f\" Fold {fold}: Acc = {accs[fold][device]:.4f}, F1 = {f1s[fold][device]:.4f}\")\n",
    "        result_10_fold_data.append({\n",
    "            \"Device\" : device,\n",
    "            \"Fold\" : fold,\n",
    "            \"Acc\" : accs[fold][device],\n",
    "            \"F1\" : f1s[fold][device]\n",
    "        })\n",
    "        result_10_fold_list[device][\"Acc\"].append(accs[fold][device])\n",
    "        result_10_fold_list[device][\"F1\"].append(f1s[fold][device])\n",
    "result_10_fold_data_df = pd.DataFrame(result_10_fold_data)\n",
    "result_10_fold_data_df.to_csv(os.path.join(models_folder, '10_fold_model_results_summary.csv'), index=False)\n",
    "result_10_fold_data_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f947981",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_10_fold_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a14066a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_10_fold_list[\"MW\"][\"Acc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1dd4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Perform the One-Way ANOVA Test ---\n",
    "f_stat, p_value = stats.f_oneway(   result_10_fold_list[\"MW\"][\"Acc\"], \n",
    "                                    result_10_fold_list[\"MU\"][\"Acc\"], \n",
    "                                    result_10_fold_list[\"IN\"][\"Acc\"], \n",
    "                                    result_10_fold_list[\"EP\"][\"Acc\"])\n",
    "\n",
    "# --- Interpret the Results ---\n",
    "print(f\"F-statistic: {f_stat:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"\\n✅ Result: Reject the null hypothesis.\")\n",
    "    print(\"Conclusion: At least one device model's mean accuracy is different\")\n",
    "else:\n",
    "    print(\"\\n❌ Result: Fail to reject the null hypothesis.\")\n",
    "    print(\"Conclusion:  All four device models have equal mean accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2fd245",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores = []\n",
    "group_labels = []\n",
    "avg_acc = 0\n",
    "for device in result_10_fold_list.keys():\n",
    "    all_scores = all_scores + result_10_fold_list[device][\"Acc\"]\n",
    "    mean_acc = np.mean(result_10_fold_list[device][\"Acc\"])\n",
    "    avg_acc = avg_acc + mean_acc\n",
    "    std_acc = np.std(result_10_fold_list[device][\"Acc\"])\n",
    "    print(f\"{device} - Mean Accuracy: {mean_acc:.4f}, Std Dev: {std_acc:.4f}\")\n",
    "\n",
    "    # Create a list of group labels that corresponds to each score\n",
    "    group_labels = group_labels + ([device] * len(result_10_fold_list[device][\"Acc\"]))\n",
    "\n",
    "all_scores\n",
    "group_labels\n",
    "avg_acc / 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317913d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc63a867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Combine all accuracy scores into one list\n",
    "# all_scores = np.concatenate([accuracies_mw, accuracies_ep, accuracies_mu, accuracies_in])\n",
    "\n",
    "# # Create a list of group labels that corresponds to each score\n",
    "# group_labels = ['MW'] * len(accuracies_mw) + \\\n",
    "#                ['EP'] * len(accuracies_ep) + \\\n",
    "#                ['MU'] * len(accuracies_mu) + \\\n",
    "#                ['IN'] * len(accuracies_in)\n",
    "\n",
    "# --- 3. Perform the Tukey's HSD test ---\n",
    "# We set alpha (the significance level) to 0.05.\n",
    "tukey_results = pairwise_tukeyhsd(endog=all_scores, groups=group_labels, alpha=0.05)\n",
    "\n",
    "# --- 4. Print and interpret the results ---\n",
    "print(\"Tukey's HSD Post-Hoc Test Results:\")\n",
    "print(tukey_results)\n",
    "\n",
    "print(\"\\n--- Interpretation Guide ---\")\n",
    "print(\"group1, group2: The pair of devices being compared.\")\n",
    "print(\"meandiff: The difference between the mean accuracies of the two groups.\")\n",
    "print(\"p-adj: The adjusted p-value for the comparison. This is the most important value.\")\n",
    "print(\"reject: 'True' if the null hypothesis for this pair should be rejected (i.e., the difference is statistically significant).\")\n",
    "print(\"\\nConclusion: Look for pairs where 'reject' is 'True' or 'p-adj' is less than 0.05.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f62805",
   "metadata": {},
   "outputs": [],
   "source": [
    "mw_df.shape, in_df.shape, ep_df.shape, mu_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3c6cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import preprocess_signal_for_viz, string2array, get_time_vector, band_pass_filter\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca4a96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "EEG_BANDS = {\n",
    "    'Delta': (0.5, 4), 'Theta': (4, 8), 'Alpha': (8, 12),\n",
    "    'Beta': (12, 30), 'Gamma': (30, 40)\n",
    "}\n",
    "DESIRED_FS = 128  # Target sampling rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1704370b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_data = string2array(mw_df.iloc[2][\"data\"])\n",
    "time_vector = get_time_vector(tmp_data, sampling_rate=512)\n",
    "tmp_code = mw_df.iloc[2][\"code\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686d33b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_normalized = preprocess_signal_for_viz(tmp_data, 512)\n",
    "tmp_normalized_timevector = get_time_vector(tmp_normalized, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8991a33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotwave(data, vector, code, title=\"Waveform\"):\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=vector, y=data, mode='lines', name='Signal'))\n",
    "    fig.update_layout(title=f\"{title} - Target number: {code}\",\n",
    "                      xaxis_title='Time (s)',\n",
    "                      yaxis_title='Amplitude',\n",
    "                      template='plotly_white')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb8fb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract bands and plot\n",
    "def plot_bands(data, original_fs=128, desired_fs=128, code=4):\n",
    "    filtered_signals = {}\n",
    "    for band, (low, high) in EEG_BANDS.items():\n",
    "        filtered = band_pass_filter(data = data, low_cut = low, high_cut = high, fs = original_fs)\n",
    "        filtered_signals[band] = filtered\n",
    "        time_vector = get_time_vector(filtered, desired_fs)\n",
    "        plotwave(filtered, time_vector, code, title=f\"{band} Band\")\n",
    "    return filtered_signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84fdf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the original signal using plotly use time vector on x-axis\n",
    "plotwave(tmp_data, time_vector, tmp_code, title=\"Original Signal\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d26fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotwave(tmp_normalized, tmp_normalized_timevector, tmp_code, title=\"Processed Signal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669b547b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "len(tmp_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846d9fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bands(tmp_normalized, original_fs=128, desired_fs=128, code=tmp_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5ed328",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73b921f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05415d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72755a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926e64e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WalshCapstone (3.11.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
