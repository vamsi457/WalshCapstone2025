{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f44389f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Importing Libraries\n",
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# ## Import Utilities\n",
    "from utilities import (\n",
    "    string2array,\n",
    "    EEGDataFrameUI,\n",
    "    display_waveform,\n",
    "    display_fft,\n",
    "    display_psd,\n",
    "    prepare_signals_for_training,\n",
    "    process_raw_signals,\n",
    "    extract_features_from_processed,\n",
    "    aggregate_multichannel_features,\n",
    "    select_best_features,\n",
    "    prepare_for_training\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e6f5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Setup Logging\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(asctime)s - %(levelname)s - %(filename)s : %(lineno)d - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49972fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82253f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join('/mnt', 'd', 'work', 'Walsh', 'Capstone', 'Published', 'Data')\n",
    "prk_folder = os.path.join(data_dir, 'parquets')\n",
    "\n",
    "# Global variables\n",
    "SAMPLING_RATES = {\n",
    "    \"MW\": 512, \n",
    "    \"EP\": 128, \n",
    "    \"MU\": 220, \n",
    "    \"IN\": 128\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53e8d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Main Pipeline Function\n",
    "def run_full_pipeline(device_name, raw_df, sampling_rate, pipeline_params, prk_folder, k_best_features=40):\n",
    "    \"\"\"\n",
    "    Executes the full, optimized, and checkpointed EEG processing pipeline for a given device.\n",
    "    \"\"\"\n",
    "    logging.info(f\"\\n--- Starting Full Pipeline for {device_name} ---\")\n",
    "    \n",
    "    # Define file paths for each stage\n",
    "    processed_file = os.path.join(prk_folder, f'{device_name}_processed.parquet')\n",
    "    features_file = os.path.join(prk_folder, f'{device_name}_features.parquet')\n",
    "    aggregated_file = os.path.join(prk_folder, f'{device_name}_aggregated.parquet')\n",
    "    model_ready_file = os.path.join(prk_folder, f'{device_name}_model_ready.parquet')\n",
    "\n",
    "    # --- Stage 1: Signal Processing ---\n",
    "    if os.path.exists(processed_file):\n",
    "        logging.info(f\"Loading existing processed data from {processed_file}\")\n",
    "        processed_df = pd.read_parquet(processed_file)\n",
    "    else:\n",
    "        logging.info(\"Stage 1: Processing raw signals...\")\n",
    "        processed_df = process_raw_signals(raw_df, sampling_rate, pipeline_params)\n",
    "        processed_df.to_parquet(processed_file, index=False)\n",
    "        logging.info(f\"Saved processed signals to {processed_file}\")\n",
    "\n",
    "    # --- Stage 2: Denoising and Feature Extraction ---\n",
    "    if os.path.exists(features_file):\n",
    "        logging.info(f\"Loading existing features data from {features_file}\")\n",
    "        features_df = pd.read_parquet(features_file)\n",
    "    else:\n",
    "        logging.info(\"Stage 2: Denoising and extracting features...\")\n",
    "        is_multichannel = device_name != \"MW\"\n",
    "        features_df = extract_features_from_processed(processed_df, pipeline_params, is_multichannel=is_multichannel, no_car=pipeline_params['no_car'])\n",
    "        features_df.to_parquet(features_file, index=False)\n",
    "        logging.info(f\"Saved features to {features_file}\")\n",
    "        \n",
    "    # --- Stage 3: Feature Aggregation ---\n",
    "    if os.path.exists(aggregated_file):\n",
    "        logging.info(f\"Loading existing aggregated data from {aggregated_file}\")\n",
    "        aggregated_df = pd.read_parquet(aggregated_file)\n",
    "    else:\n",
    "        logging.info(\"Stage 3: Aggregating features for multi-channel data...\")\n",
    "        is_multichannel = device_name != \"MW\"\n",
    "        aggregated_df = aggregate_multichannel_features(features_df, is_multichannel=is_multichannel)\n",
    "        aggregated_df.to_parquet(aggregated_file, index=False)\n",
    "        logging.info(f\"Saved aggregated features to {aggregated_file}\")\n",
    "\n",
    "    # --- Stage 4: Feature Selection ---\n",
    "    if os.path.exists(model_ready_file):\n",
    "        logging.info(f\"Loading existing model-ready data from {model_ready_file}\")\n",
    "        model_ready_df = pd.read_parquet(model_ready_file)\n",
    "    else:\n",
    "        logging.info(\"Stage 4: Selecting best features for model training...\")\n",
    "        model_ready_df = select_best_features(aggregated_df, k=k_best_features)\n",
    "        model_ready_df.to_parquet(model_ready_file, index=False)\n",
    "        logging.info(f\"Saved model-ready data to {model_ready_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2618c9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mw_pipeline_params = {\n",
    "    'target_sr': 128, 'target_duration_s': 2, 'low_cut_bp': 0.6,\n",
    "    'high_cut_bp': 60, 'notch_freq': 50, 'filter_order_bp': 5,\n",
    "    'q_factor_notch': 30.0, 'segment_selection_criteria': 'min_abs_amplitude',\n",
    "    'normalization_method': 'z-score', 'correlation_threshold': 0.9,\n",
    "    'no_car': True\n",
    "}\n",
    "\n",
    "# Load raw dataframes\n",
    "logging.info(\"Loading raw MindBigData datasets from Parquet files...\")\n",
    "mw_df = pd.read_parquet(os.path.join(prk_folder, 'MW.parquet'))\n",
    "# You can load other dataframes (mu_df, in_df, etc.) here as well\n",
    "logging.info(\"Raw datasets loaded.\")\n",
    "\n",
    "# --- Execute Pipeline for MW device (Single-channel example) ---\n",
    "run_full_pipeline(\n",
    "    device_name=\"MW\",\n",
    "    raw_df=mw_df,\n",
    "    sampling_rate=SAMPLING_RATES['MW'],\n",
    "    pipeline_params=mw_pipeline_params,\n",
    "    prk_folder=prk_folder,\n",
    "    k_best_features=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a948f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_pipeline_params = {\n",
    "    'target_sr': 128, 'target_duration_s': 2, 'low_cut_bp': 0.6,\n",
    "    'high_cut_bp': 60, 'notch_freq': 50, 'filter_order_bp': 5,\n",
    "    'q_factor_notch': 30.0, 'segment_selection_criteria': 'min_abs_amplitude',\n",
    "    'normalization_method': 'z-score', 'correlation_threshold': 0.9,\n",
    "    'no_car': True\n",
    "}\n",
    "# Load raw dataframes\n",
    "logging.info(\"Loading raw MindBigData datasets from Parquet files...\")\n",
    "mu_df = pd.read_parquet(os.path.join(prk_folder, 'MU.parquet'))\n",
    "# You can load other dataframes (mu_df, in_df, etc.) here as well\n",
    "logging.info(\"Raw datasets loaded.\")\n",
    "\n",
    "# --- Execute Pipeline for MU device (Multi-channel example) ---\n",
    "run_full_pipeline(\n",
    "    device_name=\"MU\",\n",
    "    raw_df=mu_df,\n",
    "    sampling_rate=SAMPLING_RATES['MU'],\n",
    "    pipeline_params=mu_pipeline_params,\n",
    "    prk_folder=prk_folder,\n",
    "    k_best_features=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e8d8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_pipeline_params = {\n",
    "    'target_sr': 128, 'target_duration_s': 2, 'low_cut_bp': 0.6,\n",
    "    'high_cut_bp': 60, 'notch_freq': 50, 'filter_order_bp': 5,\n",
    "    'q_factor_notch': 30.0, 'segment_selection_criteria': 'min_abs_amplitude',\n",
    "    'normalization_method': 'z-score', 'correlation_threshold': 0.9,\n",
    "    'no_car': True\n",
    "}\n",
    "# Load raw dataframes\n",
    "logging.info(\"Loading raw MindBigData datasets from Parquet files...\")\n",
    "in_df = pd.read_parquet(os.path.join(prk_folder, 'IN.parquet'))\n",
    "# You can load other dataframes (mu_df, in_df, etc.) here as well\n",
    "logging.info(\"Raw datasets loaded.\")\n",
    "\n",
    "# --- Execute Pipeline for MU device (Multi-channel example) ---\n",
    "run_full_pipeline(\n",
    "    device_name=\"IN\",\n",
    "    raw_df=in_df,\n",
    "    sampling_rate=SAMPLING_RATES['IN'],\n",
    "    pipeline_params=in_pipeline_params,\n",
    "    prk_folder=prk_folder,\n",
    "    k_best_features=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d0650e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ep_pipeline_params = {\n",
    "    'target_sr': 128, 'target_duration_s': 2, 'low_cut_bp': 0.6,\n",
    "    'high_cut_bp': 60, 'notch_freq': 50, 'filter_order_bp': 5,\n",
    "    'q_factor_notch': 30.0, 'segment_selection_criteria': 'min_abs_amplitude',\n",
    "    'normalization_method': 'z-score', 'correlation_threshold': 0.9,\n",
    "    'no_car': True\n",
    "}\n",
    "# Load raw dataframes\n",
    "logging.info(\"Loading raw MindBigData datasets from Parquet files...\")\n",
    "ep_df = pd.read_parquet(os.path.join(prk_folder, 'EP.parquet'))\n",
    "# You can load other dataframes (mu_df, in_df, etc.) here as well\n",
    "logging.info(\"Raw datasets loaded.\")\n",
    "\n",
    "# --- Execute Pipeline for MU device (Multi-channel example) ---\n",
    "run_full_pipeline(\n",
    "    device_name=\"EP\",\n",
    "    raw_df=ep_df,\n",
    "    sampling_rate=SAMPLING_RATES['EP'],\n",
    "    pipeline_params=ep_pipeline_params,\n",
    "    prk_folder=prk_folder,\n",
    "    k_best_features=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c12a276",
   "metadata": {},
   "outputs": [],
   "source": [
    "mw_df = pd.read_parquet(os.path.join(prk_folder, 'MW.parquet'))\n",
    "mu_df = pd.read_parquet(os.path.join(prk_folder, 'MU.parquet'))\n",
    "in_df = pd.read_parquet(os.path.join(prk_folder, 'IN.parquet'))\n",
    "ep_df = pd.read_parquet(os.path.join(prk_folder, 'EP.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8c738f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Optional: Interactive UI for exploring raw data ---\n",
    "# To run this, you must be in a Jupyter environment\n",
    "logging.info(\"\\nTo explore data interactively, run the following lines in a Jupyter Notebook:\")\n",
    "DATAFRAME_OPTIONS_UI = {\n",
    "    \"MW\": mw_df,\n",
    "    \"MU\": mu_df,\n",
    "    \"IN\": in_df,\n",
    "    \"EP\": ep_df\n",
    "}\n",
    "\n",
    "eeg_ui = EEGDataFrameUI(DATAFRAME_OPTIONS_UI, string2array, SAMPLING_RATES, display_waveform, display_fft, display_psd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9e8f41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WalshCapstone (3.11.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
